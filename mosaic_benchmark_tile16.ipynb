{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ðŸŽ¨ Color+Texture Mosaic â€” Performance & Scaling Report (Tile Size = 16 px)\n",
        "\n",
        "This notebook measures runtime and quality metrics of the mosaic system for different **grid sizes** and compares **vectorized** vs **loop-based** matching.\n",
        "\n",
        "**What you'll get:**\n",
        "1. A timing table for grid sizes: **16Ã—16, 32Ã—32, 64Ã—64, 128Ã—128** (vectorized pipeline)\n",
        "2. A metrics table (MSE, PSNR, SSIM variants) across the same grid sizes\n",
        "3. A comparison table of execution time: **vectorized vs loop-based** (for 16Ã—16, 32Ã—32, 64Ã—64)\n",
        "\n",
        "**Assumptions:**\n",
        "- Tile size is fixed at **16 px** (uses a prebuilt cache NPZ in `./cache/`)\n",
        "- You have at least one test image available (e.g., `./samples/your_image.jpg`)\n",
        "- Cache files follow pattern: `cache/tiles_s16_allrotflips_*.npz`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Setup (Colab-friendly)\n",
        "If running in Colab:\n",
        "\n",
        "- Upload your **`cache/`** folder that contains the `tiles_s16_allrotflips_*.npz` file(s)\n",
        "- Upload a sample image under `samples/` (or change `IMG_PATH` below)\n",
        "\n",
        "You can use the cells below to create folders and upload files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (Optional) Colab helpers: create dirs and upload files\n",
        "import os\n",
        "os.makedirs('cache', exist_ok=True)\n",
        "os.makedirs('samples', exist_ok=True)\n",
        "\n",
        "try:\n",
        "    from google.colab import files  # type: ignore\n",
        "    print(\"Colab detected. You can upload files with files.upload().\")\n",
        "    # Example: files.upload()  # Uncomment to open file picker\n",
        "except Exception:\n",
        "    print(\"Not running in Colab (or google.colab not available). Proceeding...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Imports & Core Helpers (self-contained)\n",
        "This cell defines the minimal functions needed (taken from the project) so the notebook can run standalone with just the cache + an input image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob, json, time, math\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from dataclasses import dataclass\n",
        "\n",
        "from skimage.color import rgb2lab\n",
        "from skimage.filters import sobel_h, sobel_v\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "\n",
        "CACHE_DIR = \"cache\"\n",
        "\n",
        "def load_cache_by_size(tile_size: int):\n",
        "    pattern = os.path.join(CACHE_DIR, f\"tiles_s{tile_size:02d}_allrotflips_*.npz\")\n",
        "    matches = sorted(glob.glob(pattern))\n",
        "    if not matches:\n",
        "        raise FileNotFoundError(f\"No cache for tile size {tile_size}: expected {pattern}\")\n",
        "    path = matches[-1]\n",
        "    z = np.load(path, allow_pickle=False)\n",
        "    key = json.loads(bytes(z[\"key_json\"]).decode())\n",
        "    cache = {\n",
        "        \"key\": key,\n",
        "        \"tiles\": z[\"tiles\"].astype(np.uint8),\n",
        "        \"tile_means_lab_rot\": z[\"tile_means_lab_rot\"].astype(np.float32),\n",
        "        \"tile_texture_rot\": z[\"tile_texture_rot\"].astype(np.float32),\n",
        "        \"transform_ids\": z[\"transform_ids\"].astype(np.int16),\n",
        "        \"file_index\": z[\"file_index\"].astype(np.int32),\n",
        "        \"tile_size\": int(z[\"tile_size\"]),\n",
        "    }\n",
        "    return cache\n",
        "\n",
        "def resize_and_crop_to_grid(img: np.ndarray, cell: int, grid: tuple[int, int]) -> np.ndarray:\n",
        "    gy, gx = grid\n",
        "    target_h, target_w = gy * cell, gx * cell\n",
        "    pil = Image.fromarray(img)\n",
        "    scale = max(target_w / pil.width, target_h / pil.height)\n",
        "    new_w, new_h = int(np.ceil(pil.width * scale)), int(np.ceil(pil.height * scale))\n",
        "    pil = pil.resize((new_w, new_h), Image.Resampling.LANCZOS)\n",
        "    left = (new_w - target_w) // 2\n",
        "    top = (new_h - target_h) // 2\n",
        "    pil = pil.crop((left, top, left + target_w, top + target_h))\n",
        "    return np.asarray(pil, dtype=np.uint8)\n",
        "\n",
        "def quantize_colors_pillow(img: np.ndarray, k: int = 16) -> np.ndarray:\n",
        "    if k <= 0:\n",
        "        return img\n",
        "    q = Image.fromarray(img).quantize(colors=k, method=Image.Quantize.FASTOCTREE).convert(\"RGB\")\n",
        "    return np.asarray(q, dtype=np.uint8)\n",
        "\n",
        "def cell_lab_means(img: np.ndarray, cell: int) -> np.ndarray:\n",
        "    H, W = img.shape[:2]\n",
        "    gy, gx = H // cell, W // cell\n",
        "    lab = rgb2lab(img / 255.0)\n",
        "    blocks = lab.reshape(gy, cell, gx, cell, 3).swapaxes(1, 2)\n",
        "    mu = blocks.mean(axis=(2, 3))\n",
        "    return mu.astype(np.float32)\n",
        "\n",
        "def cell_texture_scalar(img: np.ndarray, cell: int) -> np.ndarray:\n",
        "    H, W = img.shape[:2]\n",
        "    gy, gx = H // cell, W // cell\n",
        "    L = rgb2lab(img / 255.0)[..., 0].astype(np.float32)\n",
        "    gy_ = sobel_h(L)\n",
        "    gx_ = sobel_v(L)\n",
        "    mag = np.hypot(gx_, gy_)\n",
        "    blocks = mag.reshape(gy, cell, gx, cell).swapaxes(1, 2)\n",
        "    t = blocks.mean(axis=(2, 3))\n",
        "    return t.astype(np.float32)\n",
        "\n",
        "def reconstruct_mosaic(tile_idx: np.ndarray, tiles: np.ndarray) -> np.ndarray:\n",
        "    gy, gx = tile_idx.shape\n",
        "    s = tiles.shape[1]\n",
        "    out = np.zeros((gy * s, gx * s, 3), dtype=np.uint8)\n",
        "    for iy in range(gy):\n",
        "        for ix in range(gx):\n",
        "            out[iy*s:(iy+1)*s, ix*s:(ix+1)*s] = tiles[tile_idx[iy, ix]]\n",
        "    return out\n",
        "\n",
        "def mse(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    a = a.astype(np.float32)\n",
        "    b = b.astype(np.float32)\n",
        "    return float(np.mean((a - b) ** 2))\n",
        "\n",
        "def psnr_rgb(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(psnr(a, b, data_range=255))\n",
        "\n",
        "def ssim_rgb(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    return float(ssim(a, b, channel_axis=2, data_range=255))\n",
        "\n",
        "def ssim_blockwise(proc: np.ndarray, mosaic: np.ndarray, cell: int) -> float:\n",
        "    H, W = proc.shape[:2]\n",
        "    gy, gx = H // cell, W // cell\n",
        "    scores = []\n",
        "    k = min(cell, 11)\n",
        "    if k % 2 == 0:\n",
        "        k -= 1\n",
        "    k = max(3, k)\n",
        "    for iy in range(gy):\n",
        "        for ix in range(gx):\n",
        "            a = proc[iy*cell:(iy+1)*cell, ix*cell:(ix+1)*cell]\n",
        "            b = mosaic[iy*cell:(iy+1)*cell, ix*cell:(ix+1)*cell]\n",
        "            try:\n",
        "                s = ssim(a, b, channel_axis=2, data_range=255, win_size=k)\n",
        "            except Exception:\n",
        "                ag = a.mean(axis=2)\n",
        "                bg = b.mean(axis=2)\n",
        "                kk = min(k, min(ag.shape))\n",
        "                if kk % 2 == 0:\n",
        "                    kk -= 1\n",
        "                kk = max(3, kk)\n",
        "                s = ssim(ag, bg, data_range=255, win_size=kk)\n",
        "            scores.append(float(s))\n",
        "    return float(np.mean(scores)) if scores else 0.0\n",
        "\n",
        "def ssim_per_channel(a: np.ndarray, b: np.ndarray) -> tuple[float, float, float, float]:\n",
        "    rs = float(ssim(a[...,0], b[...,0], data_range=255))\n",
        "    gs = float(ssim(a[...,1], b[...,1], data_range=255))\n",
        "    bs = float(ssim(a[...,2], b[...,2], data_range=255))\n",
        "    return rs, gs, bs, float((rs + gs + bs) / 3.0)\n",
        "\n",
        "def ssim_global_gray(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    ag = a.mean(axis=2)\n",
        "    bg = b.mean(axis=2)\n",
        "    win = min(ag.shape)\n",
        "    if win % 2 == 0:\n",
        "        win -= 1\n",
        "    win = max(3, win)\n",
        "    return float(ssim(ag, bg, data_range=255, win_size=win))\n",
        "\n",
        "def ssim_multiscale_gray(a: np.ndarray, b: np.ndarray) -> float:\n",
        "    def to_gray(x):\n",
        "        return x.mean(axis=2).astype(np.float32)\n",
        "    ag, bg = to_gray(a), to_gray(b)\n",
        "    scores = []\n",
        "    for scale in (1.0, 0.5, 0.25):\n",
        "        if scale == 1.0:\n",
        "            Ag, Bg = ag, bg\n",
        "        else:\n",
        "            new_h = max(2, int(round(ag.shape[0] * scale)))\n",
        "            new_w = max(2, int(round(ag.shape[1] * scale)))\n",
        "            Ag = np.array(Image.fromarray(ag).resize((new_w, new_h), Image.Resampling.BICUBIC))\n",
        "            Bg = np.array(Image.fromarray(bg).resize((new_w, new_h), Image.Resampling.BICUBIC))\n",
        "        win = min(Ag.shape)\n",
        "        if win % 2 == 0:\n",
        "            win -= 1\n",
        "        win = max(3, win)\n",
        "        scores.append(float(ssim(Ag, Bg, data_range=255, win_size=win)))\n",
        "    return float(np.mean(scores)) if scores else 0.0\n",
        "\n",
        "def texture_aware_mapping(block_avgs, block_textures, tile_means, tile_textures, alpha=0.7):\n",
        "    gy, gx, _ = block_avgs.shape\n",
        "    B_colors = block_avgs.reshape(-1, 3)\n",
        "    B_textures = block_textures.reshape(-1)\n",
        "    color_dists = ((B_colors[:, None, :] - tile_means[None, :, :]) ** 2).sum(axis=2)\n",
        "    texture_dists = (B_textures[:, None] - tile_textures[None, :]) ** 2\n",
        "    color_dists = color_dists / (color_dists.max() + 1e-8)\n",
        "    texture_dists = texture_dists / (texture_dists.max() + 1e-8)\n",
        "    combined = alpha * color_dists + (1 - alpha) * texture_dists\n",
        "    idx = combined.argmin(axis=1).reshape(gy, gx)\n",
        "    return idx.astype(np.int32)\n",
        "\n",
        "def match_color_texture_naive(mu_lab, tex, tile_means, tile_textures, alpha=0.7):\n",
        "    \"\"\"Naive Python-loop version (for timing comparison).\"\"\"\n",
        "    gy, gx, _ = mu_lab.shape\n",
        "    Bc = mu_lab.reshape(-1, 3)\n",
        "    Bt = tex.reshape(-1)\n",
        "    T = tile_means\n",
        "    U = tile_textures\n",
        "    B = Bc.shape[0]\n",
        "    Tn = T.shape[0]\n",
        "    # compute maxima for normalization\n",
        "    color_raw_max = 0.0\n",
        "    text_raw_max = 0.0\n",
        "    for i in range(B):\n",
        "        for j in range(Tn):\n",
        "            cd = float(np.sum((Bc[i] - T[j])**2))\n",
        "            td = float((Bt[i] - U[j])**2)\n",
        "            if cd > color_raw_max: color_raw_max = cd\n",
        "            if td > text_raw_max: text_raw_max = td\n",
        "    color_norm = max(color_raw_max, 1e-8)\n",
        "    text_norm = max(text_raw_max, 1e-8)\n",
        "    idx_flat = np.empty(B, dtype=np.int32)\n",
        "    for i in range(B):\n",
        "        best_j, best_d = -1, float(\"inf\")\n",
        "        for j in range(Tn):\n",
        "            cd = float(np.sum((Bc[i] - T[j])**2)) / color_norm\n",
        "            td = float((Bt[i] - U[j])**2) / text_norm\n",
        "            d = alpha * cd + (1 - alpha) * td\n",
        "            if d < best_d:\n",
        "                best_d = d\n",
        "                best_j = j\n",
        "        idx_flat[i] = best_j\n",
        "    return idx_flat.reshape(gy, gx)\n",
        "\n",
        "@dataclass\n",
        "class Timing:\n",
        "    preprocess: float\n",
        "    features: float\n",
        "    match: float\n",
        "    reconstruct: float\n",
        "    total: float\n",
        "\n",
        "def run_once(image_rgb, grid, tile_size, quant_k, alpha, tile_means, tile_textures, tiles, vectorized=True, do_metrics=True):\n",
        "    rows, cols = grid\n",
        "    t0 = time.perf_counter()\n",
        "    # preprocess\n",
        "    t1 = time.perf_counter()\n",
        "    proc = resize_and_crop_to_grid(image_rgb, cell=tile_size, grid=(rows, cols))\n",
        "    if quant_k > 0:\n",
        "        proc = quantize_colors_pillow(proc, k=quant_k)\n",
        "    t_pre = time.perf_counter() - t1\n",
        "    # features\n",
        "    t2 = time.perf_counter()\n",
        "    mu_lab = cell_lab_means(proc, tile_size)\n",
        "    tex = cell_texture_scalar(proc, tile_size)\n",
        "    t_feat = time.perf_counter() - t2\n",
        "    # matching\n",
        "    t3 = time.perf_counter()\n",
        "    if vectorized:\n",
        "        idx = texture_aware_mapping(mu_lab, tex, tile_means, tile_textures, alpha)\n",
        "    else:\n",
        "        idx = match_color_texture_naive(mu_lab, tex, tile_means, tile_textures, alpha)\n",
        "    t_match = time.perf_counter() - t3\n",
        "    # reconstruct\n",
        "    t4 = time.perf_counter()\n",
        "    mosaic = reconstruct_mosaic(idx, tiles)\n",
        "    t_reco = time.perf_counter() - t4\n",
        "    total = time.perf_counter() - t0\n",
        "\n",
        "    metrics = {}\n",
        "    if do_metrics:\n",
        "        metrics = {\n",
        "            \"MSE\": mse(proc, mosaic),\n",
        "            \"PSNR\": psnr_rgb(proc, mosaic),\n",
        "            \"SSIM_pixel\": ssim_rgb(proc, mosaic),\n",
        "            \"SSIM_block\": ssim_blockwise(proc, mosaic, tile_size),\n",
        "            \"SSIM_global_gray\": ssim_global_gray(proc, mosaic),\n",
        "            \"SSIM_multiscale_gray\": ssim_multiscale_gray(proc, mosaic),\n",
        "        }\n",
        "    return mosaic, Timing(t_pre, t_feat, t_match, t_reco, total), proc, metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Experiment Config\n",
        "- Tile size fixed to **16 px**\n",
        "- Grids: 16Ã—16, 32Ã—32, 64Ã—64, 128Ã—128\n",
        "- Repeat runs for stability (adjust `REPEATS` if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "TILE_SIZE = 16\n",
        "ALPHA = 0.7\n",
        "GRIDS = [(16,16),(32,32),(64,64),(128,128)]\n",
        "REPEATS = 3  # increase to 5 for more stable averages\n",
        "QUANT_K = 0  # keep off for timing fairness\n",
        "\n",
        "# Choose one sample image\n",
        "IMG_PATH = \"samples/beach.jpg\"  # change path as needed\n",
        "img_rgb = np.asarray(Image.open(IMG_PATH).convert(\"RGB\"), dtype=np.uint8)\n",
        "\n",
        "cache = load_cache_by_size(TILE_SIZE)\n",
        "tiles = cache[\"tiles\"]\n",
        "tile_means = cache[\"tile_means_lab_rot\"]\n",
        "tile_textures = cache[\"tile_texture_rot\"]\n",
        "print(\"Loaded cache with tiles:\", tiles.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Timing across grid sizes (vectorized pipeline)\n",
        "This produces a table with timings per stage and total time for each grid size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows = []\n",
        "for (gy,gx) in GRIDS:\n",
        "    totals = []\n",
        "    pre_list, feat_list, match_list, reco_list, total_list = [], [], [], [], []\n",
        "    for _ in range(REPEATS):\n",
        "        _, t, _, _ = run_once(img_rgb, (gy,gx), TILE_SIZE, QUANT_K, ALPHA,\n",
        "                              tile_means, tile_textures, tiles, vectorized=True, do_metrics=False)\n",
        "        pre_list.append(t.preprocess)\n",
        "        feat_list.append(t.features)\n",
        "        match_list.append(t.match)\n",
        "        reco_list.append(t.reconstruct)\n",
        "        total_list.append(t.total)\n",
        "    rows.append({\n",
        "        \"Grid\": f\"{gy}x{gx}\",\n",
        "        \"Blocks(B)\": gy*gx,\n",
        "        \"Preprocess(s)\": np.mean(pre_list),\n",
        "        \"Features(s)\": np.mean(feat_list),\n",
        "        \"Matching(s)\": np.mean(match_list),\n",
        "        \"Reconstruct(s)\": np.mean(reco_list),\n",
        "        \"Total(s)\": np.mean(total_list),\n",
        "    })\n",
        "timing_table = pd.DataFrame(rows)\n",
        "display(timing_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Quality metrics across grid sizes (vectorized pipeline)\n",
        "Computes MSE, PSNR, and SSIM variants for each grid size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metrics_rows = []\n",
        "for (gy,gx) in GRIDS:\n",
        "    # single run per grid for metrics (can average if you prefer)\n",
        "    mosaic, t, proc, mets = run_once(img_rgb, (gy,gx), TILE_SIZE, QUANT_K, ALPHA,\n",
        "                                     tile_means, tile_textures, tiles, vectorized=True, do_metrics=True)\n",
        "    metrics_rows.append({\n",
        "        \"Grid\": f\"{gy}x{gx}\",\n",
        "        \"Blocks(B)\": gy*gx,\n",
        "        \"MSE\": mets[\"MSE\"],\n",
        "        \"PSNR(dB)\": mets[\"PSNR\"],\n",
        "        \"SSIM_pixel\": mets[\"SSIM_pixel\"],\n",
        "        \"SSIM_block\": mets[\"SSIM_block\"],\n",
        "        \"SSIM_global_gray\": mets[\"SSIM_global_gray\"],\n",
        "        \"SSIM_multiscale_gray\": mets[\"SSIM_multiscale_gray\"],\n",
        "    })\n",
        "metrics_table = pd.DataFrame(metrics_rows)\n",
        "display(metrics_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Vectorized vs Loop-based comparison (16Ã—16, 32Ã—32, 64Ã—64)\n",
        "We compare matching time and total time. (Loop-based can be slow for large grids; we omit 128Ã—128.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "GRIDS_COMPARE = [(16,16),(32,32),(64,64)]\n",
        "rows_cmp = []\n",
        "for (gy,gx) in GRIDS_COMPARE:\n",
        "    # vectorized\n",
        "    _, t_vec, _, _ = run_once(img_rgb, (gy,gx), TILE_SIZE, QUANT_K, ALPHA,\n",
        "                              tile_means, tile_textures, tiles, vectorized=True, do_metrics=False)\n",
        "    # loop-based\n",
        "    _, t_loop, _, _ = run_once(img_rgb, (gy,gx), TILE_SIZE, QUANT_K, ALPHA,\n",
        "                               tile_means, tile_textures, tiles, vectorized=False, do_metrics=False)\n",
        "    rows_cmp.append({\n",
        "        \"Grid\": f\"{gy}x{gx}\",\n",
        "        \"Blocks(B)\": gy*gx,\n",
        "        \"Matching Vec (s)\": t_vec.match,\n",
        "        \"Matching Loop (s)\": t_loop.match,\n",
        "        \"Total Vec (s)\": t_vec.total,\n",
        "        \"Total Loop (s)\": t_loop.total,\n",
        "        \"Speedup (match)\": t_loop.match / max(t_vec.match, 1e-9),\n",
        "        \"Speedup (total)\": t_loop.total / max(t_vec.total, 1e-9),\n",
        "    })\n",
        "compare_table = pd.DataFrame(rows_cmp)\n",
        "display(compare_table)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Scaling analysis (brief)\n",
        "We estimate how matching time scales with the number of blocks `B = rowsÃ—cols` using a logâ€“log linear fit."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_fit(x, y):\n",
        "    lx = np.log(np.asarray(x, dtype=np.float64))\n",
        "    ly = np.log(np.asarray(y, dtype=np.float64))\n",
        "    k, b = np.polyfit(lx, ly, deg=1)  # y â‰ˆ e^b * x^k\n",
        "    return float(k), float(math.exp(b))\n",
        "\n",
        "# use vectorized matching times from timing_table\n",
        "Bs = timing_table[\"Blocks(B)\"].tolist()\n",
        "vec_match_times = timing_table[\"Matching(s)\"].tolist()\n",
        "k_vec, c_vec = log_fit(Bs, vec_match_times)\n",
        "\n",
        "analysis_text = (\n",
        "    f\"Vectorized matching scales approximately as T(B) â‰ˆ {c_vec:.3g} * B^{k_vec:.2f}.\\n\"\n",
        "    f\"(Here B is the number of grid cells; tile count is fixed by the cache.)\"\n",
        ")\n",
        "print(analysis_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Optional: Quick plots (if you want visuals)\n",
        "These are optional to include in the report."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(6,4))\n",
        "plt.plot(timing_table[\"Blocks(B)\"], timing_table[\"Total(s)\"], marker='o', label='Total (vectorized)')\n",
        "plt.plot(timing_table[\"Blocks(B)\"], timing_table[\"Matching(s)\"], marker='o', label='Matching (vectorized)')\n",
        "plt.xlabel('Blocks B = rowsÃ—cols')\n",
        "plt.ylabel('Time (s)')\n",
        "plt.title('Scaling with Grid Size (Tile=16)')\n",
        "plt.grid(True)\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "name": "mosaic_benchmark_tile16.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}